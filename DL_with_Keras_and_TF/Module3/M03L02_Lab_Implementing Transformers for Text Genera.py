# jupyter nbconvert --to script "M03L02_Lab_Implementing Transformers for Text Genera.ipynb"
#!/usr/bin/env python
# coding: utf-8

# <p style="text-align:center">
#     <a href="https://skills.network" target="_blank">
#     <img src="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png" width="200" alt="Skills Network Logo"  />
#     </a>
# </p>
# 

# # **Lab: Implementing Transformers for Text Generation**
# 

# Estimated time needed: **30** minutes
# 

# In this lab, you will learn to implement Transformers for text generation tasks. 
# 

# ## Learning Objectives
# 
# - Implement Transformers for text generation tasks 
# 
# - Build, train, and evaluate Transformer models for text generation using TensorFlow and Keras 
# 
# - Apply text generation in real-world scenarios 
# 

# ----
# 

# ### Step-by-step instructions 
# 
# #### Step 1: Set up the environment 
# 
# - Import necessary libraries and load the data set 
# 
# - Preprocess the dataset for training 
# 
# In the following code: 
# 
# - Import TensorFlow and other necessary libraries. 
# 
# - Load the Shakespeare text dataset. 
# 
# - Preprocess the data set using the TextVectorization layer to convert text into integer sequences. 
# 

# In[10]:


#get_ipython().system('pip install tensorflow==2.16.2')


# In[11]:


import tensorflow as tf 
import numpy as np 
from tensorflow.keras.layers import TextVectorization 
from tensorflow.keras.utils import get_file 


# In[12]:


# Load the dataset 
path_to_file = get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt') 
text = open(path_to_file, 'rb').read().decode(encoding='utf-8') 

# Preview the dataset 
print(text[:1000]) 


# In[13]:


# Preprocess the dataset 
vocab_size = 10000 
seq_length = 100 

# Adapt TextVectorization to full text 
vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int') 
text_ds = tf.data.Dataset.from_tensor_slices([text]).batch(1) 
vectorizer.adapt(text_ds) 

# Vectorize the text 
vectorized_text = vectorizer([text])[0] 
print("Vectorized text shape:", vectorized_text.shape) 
print("First 10 vectorized tokens:", vectorized_text.numpy()[:10]) 


# #### Step 2: Create input and target sequences 
# 
# Generate input and target sequences for training the Transformer model. 
# 
# In the following code: 
# 
# - Define a function to generate input and target sequences. 
# 
# - Split the text data into sequences of the specified length. 
# 
# - Convert the sequences into TensorFlow tensors for training. 
# 
# Generative sequence: 
# 

# In[14]:


def create_sequences(text, seq_length): 
    input_seqs = [] 
    target_seqs = [] 
    for i in range(len(text) - seq_length): 
        input_seq = text[i:i + seq_length] 
        target_seq = text[i + 1:i + seq_length + 1] 
        input_seqs.append(input_seq) 
        target_seqs.append(target_seq) 
    return np.array(input_seqs), np.array(target_seqs) 

# Generate sequences 
X, Y = create_sequences(vectorized_text.numpy(), seq_length) 

# Check if sequences are correctly generated 
print("Number of sequences generated:", len(X)) 
print("Sample input sequence:", X[0] if len(X) > 0 else "No sequences generated") 

# Check if X and Y are not empty 
assert X.size > 0, "Input data X is empty" 
assert Y.size > 0, "Target data Y is empty" 
X = tf.convert_to_tensor(X) 
Y = tf.convert_to_tensor(Y) 
print("Shape of X:", X.shape) 
print("Shape of Y:", Y.shape)


# #### Step 3: Build the Transformer model 
# 
# Define the Transformer model architecture for text generation. 
# 
# In the following code: 
# 
# - Define the TransformerBlock class that includes multi-head attention and feedforward layers with normalization and dropout. 
# 
# - Define the TransformerModel class, including embedding, positional encoding, and multiple Transformer blocks. 
# 
# - Compile the Transformer model using the Adam optimizer and sparse categorical cross-entropy loss function. 
# 
# Transformer model: 
# 

# In[15]:


from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, LayerNormalization, Dropout
from tensorflow.keras.models import Model

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim),
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, inputs, training=False):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class TransformerModel(Model):  # Model is now properly imported
    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length):
        super(TransformerModel, self).__init__()
        self.embedding = Embedding(vocab_size, embed_dim)
        self.pos_encoding = self.positional_encoding(seq_length, embed_dim)
        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)]
        self.dense = Dense(vocab_size)

    def positional_encoding(self, seq_length, embed_dim):
        angle_rads = self.get_angles(np.arange(seq_length)[:, np.newaxis], np.arange(embed_dim)[np.newaxis, :], embed_dim)
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def get_angles(self, pos, i, embed_dim):
        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))
        return pos * angle_rates

    def call(self, inputs, training=False):
        seq_len = tf.shape(inputs)[1]
        x = self.embedding(inputs)
        x += self.pos_encoding[:, :seq_len, :]
        for transformer_block in self.transformer_blocks:
            x = transformer_block(x, training=training)  # Pass training argument correctly
        output = self.dense(x)
        return output


# In[16]:


# Hyperparameters 
embed_dim = 256 
num_heads = 4 
ff_dim = 512 
num_layers = 4 

# Build the Transformer model 
model = TransformerModel(vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length)

# Provide input shape to build the model by passing a dummy input with maxval specified
_ = model(tf.random.uniform((1, seq_length), maxval=vocab_size, dtype=tf.int32))

# Compile the model 
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

# Summary of the model 
model.summary()


# #### Step 4: Train the Transformer model 
# 
# Train the Transformer model on the preprocessed text data. 
# 
# In the following code: 
# 
# - Train the Transformer model on the input and target sequences 
# 
# - Plot the training loss to monitor the model's performance over epochs 
# 
# Model training: 
# 

# In[17]:


#get_ipython().system('pip install matplotlib')


# In[ ]:


# Import necessary libraries for training visualization
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping

# Early stopping callback to stop training if the loss doesn't improve
early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)

# Train the transformer model on the full input and target sequences
history = model.fit(X, Y, epochs=20, batch_size=32, callbacks=[early_stopping])

# Plot training loss to monitor model performance over epochs
plt.plot(history.history['loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.show()


# #### Step 5: Generate text with the trained model 
# 
# Define a function to generate text using the trained Transformer model. 
# 
# In the following code: 
# 
# - Define the generate_text function to generate text using the trained Transformer model 
# 
# - Convert the start string into numerical format 
# 
# - Use the model to predict the next word and append it to the generated text 
# 
# - Print the generated text 
# 
# #### Text generation: 
# 

# In[ ]:


def generate_text(model, start_string, num_generate=100, temperature=1.0):
    # Convert the start string to a vectorized format
    input_eval = vectorizer([start_string]).numpy()
    
    # Ensure the input length is the same as the model's expected input shape
    if input_eval.shape[1] < seq_length:
        # Pad the input if it's shorter than the expected sequence length
        padding = np.zeros((1, seq_length - input_eval.shape[1]))
        input_eval = np.concatenate((padding, input_eval), axis=1)
    elif input_eval.shape[1] > seq_length:
        # Truncate the input if it's longer than the expected sequence length
        input_eval = input_eval[:, -seq_length:]

    input_eval = tf.convert_to_tensor(input_eval)
    
    # Initialize an empty list to store generated text
    text_generated = []

    # Start generating text
    for i in range(num_generate):
        # Make predictions using the model
        predictions = model(input_eval)

        # Remove only the batch dimension, keep the logits as 2D (batch_size, vocab_size)
        predictions = predictions[0]  # This should be of shape [vocab_size]

        # Apply temperature to predictions
        predictions = predictions / temperature
        
        # Use a categorical distribution to predict the next word
        predicted_id = tf.random.categorical(predictions, num_samples=1)[0, 0].numpy()

        # Update the input tensor to include the predicted word, maintaining the sequence length
        input_eval = np.append(input_eval.numpy(), [[predicted_id]], axis=1)  # Append predicted token
        input_eval = input_eval[:, -seq_length:]  # Keep only the last `seq_length` tokens
        input_eval = tf.convert_to_tensor(input_eval)  # Convert back to tensor

        # Append the predicted word to the generated text
        text_generated.append(vectorizer.get_vocabulary()[predicted_id])

    # Return the generated text starting from the initial seed
    return start_string + ' ' + ' '.join(text_generated)

# Generate text with temperature control
start_string = "To be, or not to be"
generated_text = generate_text(model, start_string, temperature=0.7)  # Lower temperature for more focused predictions
print(generated_text)


# ### Practice exercises 
# 
# ### Exercise 1: Experiment with different sequence lengths 
# 
# **Objective:** Implement different sequence lengths to understand their effect on the performance of the Transformer model. 
# 
# **Instructions:**
# 
# - Change the sequence length to 50 
# 
# - Preprocess the data set with the new sequence length 
# 
# - Train the model and compare the training loss 
# 

# In[ ]:


# Write your code here


# <details>
#     <summary>Click here for Solution</summary>
# 
# ```python
# !pip install pandas
# !pip install scikit-learn
# 
# import numpy as np
# import pandas as pd
# import tensorflow as tf
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.model_selection import train_test_split
# from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input
# from tensorflow.keras.callbacks import EarlyStopping
# import matplotlib.pyplot as plt
# 
# # Example: Load a time-series dataset
# data_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WHA_mc9FWSVjCGLSLAp48A/stock-prices.csv'
# df = pd.read_csv(data_url)
# 
# # Select the 'Close' column for training (or any relevant column for your task)
# data = df[['Close']].values
# 
# # Normalize the data
# scaler = MinMaxScaler(feature_range=(0, 1))
# data = scaler.fit_transform(data)
# 
# # Check the number of samples in the data
# n_samples = data.shape[0]
# print(f"Number of samples in the dataset: {n_samples}")
# 
# # Ensure we have enough data by setting a reasonable train size
# if n_samples < 100:
#     print("Dataset is very small. Using 50% of the data for training.")
#     train_size = 0.5  # Use 50% of data if we have less than 100 samples
#     seq_length = 5    # Use a shorter sequence length for very small datasets
# else:
#     train_size = 0.1  # Use 10% of data for larger datasets
#     seq_length = 50   # Change sequence length to 50 for larger datasets
# 
# # Reduce dataset size for quicker runs
# X, _, Y, _ = train_test_split(data, data, train_size=train_size, random_state=42)  # Adjust train_size based on data
# 
# # Preprocess the dataset with adjusted sequence length
# def create_dataset(data, time_step=seq_length):
#     X, Y = [], []
#     for i in range(len(data)-time_step-1):
#         a = data[i:(i+time_step), 0]
#         X.append(a)
#         Y.append(data[i + time_step, 0])
#     return np.array(X), np.array(Y)
# 
# X, Y = create_dataset(data, seq_length)
# 
# # Check if the generated sequences have valid shapes
# if X.size == 0 or Y.size == 0:
#     raise ValueError(f"The dataset is too small to create sequences with a length of {seq_length}. Reduce the sequence length or use a larger dataset.")
# 
# X = X.reshape(X.shape[0], X.shape[1], 1)
# 
# print("Shape of X:", X.shape)
# print("Shape of Y:", Y.shape)
# 
# # Define a simpler Transformer Block for faster runs
# class TransformerBlock(Layer):
#     def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
#         super(TransformerBlock, self).__init__()
#         self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
#         self.ffn = tf.keras.Sequential([
#             Dense(ff_dim, activation="relu"),
#             Dense(embed_dim),
#         ])
#         self.layernorm1 = LayerNormalization(epsilon=1e-6)
#         self.layernorm2 = LayerNormalization(epsilon=1e-6)
#         self.dropout1 = Dropout(rate)
#         self.dropout2 = Dropout(rate)
# 
#     def call(self, inputs, training=False):  # Set training argument default to False
#         attn_output = self.att(inputs, inputs)
#         attn_output = self.dropout1(attn_output, training=training)
#         out1 = self.layernorm1(inputs + attn_output)
#         ffn_output = self.ffn(out1)
#         ffn_output = self.dropout2(ffn_output, training=training)
#         return self.layernorm2(out1 + ffn_output)
# 
# # Build and compile the model
# input_shape = (X.shape[1], X.shape[2])
# inputs = tf.keras.Input(shape=input_shape)
# x = tf.keras.layers.Dense(64)(inputs)  # Reduced embed_dim for faster runs
# transformer_block = TransformerBlock(embed_dim=64, num_heads=4, ff_dim=128)  # Reduced model complexity
# x = transformer_block(x, training=True)  # Pass training argument here
# flatten = tf.keras.layers.Flatten()(x)
# outputs = tf.keras.layers.Dense(1)(flatten)
# model = tf.keras.Model(inputs, outputs)
# 
# model.compile(optimizer='adam', loss='mse')
# 
# # Early stopping to stop training when no improvement is seen
# early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)
# 
# # Train the model with reduced epochs and steps
# history = model.fit(X, Y, epochs=5, batch_size=32, steps_per_epoch=10, callbacks=[early_stopping])  # Reduced epochs and steps per epoch
# 
# # Plot training loss
# plt.plot(history.history['loss'])
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.title('Training Loss')
# plt.show()
# 
# ```
# 
# </details>
# 

# ### Exercise 2: Add a learning rate scheduler 
# 
# **Objective:** Implement a learning rate scheduler to adjust the learning rate during training. 
# 
# **Instructions:**
# 
# - Define a learning rate scheduler that reduces the learning rate by half every 10 epochs 
# 
# - Train the model with the learning rate scheduler and compare the training loss 
# 

# In[ ]:


# Write your code here


# <details>
#     <summary>Click here for Solution</summary>
# 
# ```python
# import numpy as np
# import pandas as pd
# import tensorflow as tf
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.model_selection import train_test_split
# from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input
# from tensorflow.keras.callbacks import EarlyStopping
# import matplotlib.pyplot as plt
# 
# # Define a learning rate scheduler  
# def scheduler(epoch, lr):  
#     if epoch % 10 == 0 and epoch != 0:  
#         lr = lr * 0.5  
#     return lr  
#  
# 
# callback = tf.keras.callbacks.LearningRateScheduler(scheduler)  
# 
# 
# # Train the model with the learning rate scheduler  
# history = model.fit(X, Y, epochs=20, batch_size=64, callbacks=[callback])  
#    
# 
# # Plot the training loss  
# plt.plot(history.history['loss'])  
# plt.xlabel('Epoch')  
# plt.ylabel('Loss')  
# plt.title('Training Loss with Learning Rate Scheduler')  
# plt.show() 
# ```
# 
# </details>
# 

# ### Exercise 3: Generate longer text sequences 
# 
# **Objective:** To explore the model's text generation capabilities and generate longer sequences. 
# 
# **Instructions:**
# 
# - Modify the `generate_text` function to generate 200 tokens instead of 100 
# 
# - Generate text using the trained model and the modified function 
# 

# In[ ]:


# Write your code here


# <details>
#     <summary>Click here for Solution</summary>
# 
# ```python
# 
# import numpy as np
# import pandas as pd
# import tensorflow as tf
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.model_selection import train_test_split
# from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input
# from tensorflow.keras.callbacks import EarlyStopping
# import matplotlib.pyplot as plt
# 
# def generate_text(model, start_string, num_generate=200):
#     # Convert the start string to numbers (vectorize)
#     input_eval = vectorizer([start_string]).numpy()
# 
#     # Ensure the input tensor has the correct shape
#     input_eval = tf.convert_to_tensor(input_eval[:, -5:])  # Ensure it has a shape of (1, 5)
#     
#     text_generated = []
# 
#     for i in range(num_generate):
#         # Make predictions using the model
#         predictions = model(input_eval)
# 
#         # Ensure predictions is a matrix with shape [batch_size, num_classes]
#         predictions = tf.squeeze(predictions, 0)  # Remove the batch dimension
#         predictions = tf.expand_dims(predictions, 0)  # Add back a batch dimension for categorical
#         
#         # Use a categorical distribution to predict the next word
#         predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()
# 
#         # Update the input tensor to include the predicted word, maintaining the sequence length
#         input_eval = np.append(input_eval.numpy(), [[predicted_id]], axis=1)  # Append predicted token
#         input_eval = input_eval[:, -5:]  # Keep only the last 5 tokens to match input shape
#         input_eval = tf.convert_to_tensor(input_eval)  # Convert back to tensor
#         
#         # Add the predicted word to the generated text
#         text_generated.append(vectorizer.get_vocabulary()[predicted_id])
# 
#     return start_string + ' ' + ' '.join(text_generated)
# 
# 
# # Generate longer text
# start_string = "To be, or not to be"
# generated_text = generate_text(model, start_string)
# 
# print(generated_text)
#  
# ```
# 
# </details>
# 

# #### Conclusion 
# 
# Congratulations on completing this lab! You have successfully built and trained a Transformer model for text generation in this lab using TensorFlow and Keras. You learned how to preprocess text data, create input and target sequences, define the Transformer model architecture, train the model, and generate text using the trained model. By completing this lab, you gained hands-on experience with Transformers for text generation and explored practical applications of this robust model architecture. 
# 

# Copyright © IBM Corporation. All rights reserved.
# 
